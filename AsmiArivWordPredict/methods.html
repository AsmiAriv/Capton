<h1>Methods Used</h1>
<p>The data has been trained using various methods, such as:<br>
<i>Term Frequency</i><br>
<i>Inverse Document Frequency</i><br>
<i>Cosine similarities</i><br></p>

<p>Finally, the data was transformed into various n-grams, such as:<br>
<b>Unigram</b><br>
<b>Bigram</b><br>
<b>Trigram</b><br>
<b>Quadrigram</b><br></p>

<p>Before training the data, it was cleaned using various regular expression and tokenizing techniques.</p>

<p>Before arriving at ngram model, other models were also tried (such as dot-product), but were found to be
quite expensive in terms of file size and computation time. Hence, n-gram was finalized considering the space and time constraints.</p>